diff --git a/examples/nvector/cuda/test_nvector_cuda.cu b/examples/nvector/cuda/test_nvector_cuda.cu
index 63787467d..2178b32b8 100644
--- a/examples/nvector/cuda/test_nvector_cuda.cu
+++ b/examples/nvector/cuda/test_nvector_cuda.cu
@@ -18,17 +18,26 @@
 #include <stdio.h>
 #include <stdlib.h>
 
+#include <sundials/sundials_math.h>
 #include <sundials/sundials_types.h>
 #include <nvector/nvector_cuda.h>
-#include <sundials/sundials_math.h>
+#include <nvector/cuda/ThreadPartitioning.hpp>
 #include "test_nvector.h"
 
+
+using namespace suncudavec;
+
+/* private custom allocator functions */
+static void* sunalloc(size_t);
+static void sunfree(void* ptr);
+
 /* CUDA vector specific tests */
-int Test_N_VMake_Cuda(N_Vector X, sunindextype length, int myid);
-int Test_N_VMakeManaged_Cuda(N_Vector X, sunindextype length, int myid);
+static int Test_N_VMake_Cuda(N_Vector X, sunindextype length, int myid);
+static int Test_N_VMakeManaged_Cuda(N_Vector X, sunindextype length, int myid);
+static int Test_N_VSetPartitioning_Cuda(N_Vector X, sunindextype length, int myid);
 
 /* CUDA vector can use unmanaged or managed memory */
-enum mem_type { UNMANAGED, MANAGED };
+enum mem_type { UNMANAGED, MANAGED, CUSTOM };
 
 /* ----------------------------------------------------------------------
  * Main NVector Testing Routine
@@ -58,16 +67,20 @@ int main(int argc, char *argv[])
   SetTiming(print_timing, 0);
 
   /* test with unmanaged and managed memory */
-  for (i=UNMANAGED; i<=MANAGED; ++i) {
+  for (i=UNMANAGED; i<=CUSTOM; ++i) {
     if (i==UNMANAGED) {
       printf("Testing CUDA N_Vector \n");
-    } else {
+    } else if (i==MANAGED) {
       printf("\nTesting CUDA N_Vector with managed memory \n");
+    } else {
+      printf("\nTesting CUDA N_Vector with custom allocator \n");
     }
     printf("Vector length %ld \n\n", (long int) length);
 
     /* Create new vectors */
-    X = (i==UNMANAGED) ? N_VNew_Cuda(length) : N_VNewManaged_Cuda(length);
+    if (i == UNMANAGED)    X = N_VNew_Cuda(length);
+    else if (i == MANAGED) X = N_VNewManaged_Cuda(length);
+    else                   X = N_VMakeWithAllocator_Cuda(length, sunalloc, sunfree);
     if (X == NULL) {
       printf("FAIL: Unable to create a new vector \n\n");
       return(1);
@@ -131,7 +144,13 @@ int main(int argc, char *argv[])
     printf("\nTesting fused and vector array operations (disabled):\n\n");
 
     /* create vector and disable all fused and vector array operations */
-    U = (i==UNMANAGED) ? N_VNew_Cuda(length) : N_VNewManaged_Cuda(length);
+    if (i == UNMANAGED)    U = N_VNew_Cuda(length);
+    else if (i == MANAGED) U = N_VNewManaged_Cuda(length);
+    else                   U = N_VMakeWithAllocator_Cuda(length, sunalloc, sunfree);
+    if (X == NULL) {
+      printf("FAIL: Unable to create a new vector \n\n");
+      return(1);
+    }
     retval = N_VEnableFusedOps_Cuda(U, SUNFALSE);
     if (U == NULL || retval != 0) {
       N_VDestroy(X);
@@ -159,7 +178,9 @@ int main(int argc, char *argv[])
     printf("\nTesting fused and vector array operations (enabled):\n\n");
 
     /* create vector and enable all fused and vector array operations */
-    V = (i==UNMANAGED) ? N_VNew_Cuda(length) : N_VNewManaged_Cuda(length);
+    if (i == UNMANAGED)    V = N_VNew_Cuda(length);
+    else if (i == MANAGED) V = N_VNewManaged_Cuda(length);
+    else                   V = N_VMakeWithAllocator_Cuda(length, sunalloc, sunfree);
     retval = N_VEnableFusedOps_Cuda(V, SUNTRUE);
     if (V == NULL || retval != 0) {
       N_VDestroy(X);
@@ -197,13 +218,13 @@ int main(int argc, char *argv[])
     fails += Test_N_VConstrMaskLocal(X, Y, Z, length, 0);
     fails += Test_N_VMinQuotientLocal(X, Y, length, 0);
 
-
     /* CUDA specific tests */
     if (i==UNMANAGED) {
       fails += Test_N_VMake_Cuda(X, length, 0);
-    } else {
+    } else if (i==MANAGED) {
       fails += Test_N_VMakeManaged_Cuda(X, length, 0);
     }
+    fails += Test_N_VSetPartitioning_Cuda(X, length, 0);
 
     /* Free vectors */
     N_VDestroy(X);
@@ -243,7 +264,7 @@ int Test_N_VMake_Cuda(N_Vector X, sunindextype length, int myid)
 
   h_data = N_VGetHostArrayPointer_Cuda(X);
   d_data = N_VGetDeviceArrayPointer_Cuda(X);
-
+  
   /* Case 1: h_data and d_data are not null */
   Y = N_VMake_Cuda(length, h_data, d_data);
   if (Y == NULL) {
@@ -314,7 +335,6 @@ int Test_N_VMakeManaged_Cuda(N_Vector X, sunindextype length, int myid)
   }
 
   N_VConst(NEG_HALF, X);
-
   vdata = N_VGetHostArrayPointer_Cuda(X);
 
   /* Case 1: data is not null */
@@ -345,6 +365,68 @@ int Test_N_VMakeManaged_Cuda(N_Vector X, sunindextype length, int myid)
 }
 
 
+int Test_N_VSetPartitioning_Cuda(N_Vector X, sunindextype length, int myid)
+{
+  N_Vector Y;
+  realtype ans, sol;
+  realtype *h_buffer, *d_buffer;
+  size_t buffer_size;
+  unsigned block = 128;
+
+  Y = N_VClone(X);
+  if (Y == NULL) {
+    printf(">>> FAILED test -- N_VClone, Proc %d \n", myid);
+    printf("    Vector is NULL \n \n");
+    return(1);
+  }
+
+  /* Case 1: create ReducePartitioning with user-provided internal buffer */
+
+  buffer_size = ReducePartitioning<realtype, sunindextype>::calcBufferSize(length, block);
+  cudaMalloc((void**) &d_buffer, buffer_size);
+  h_buffer = (realtype *) malloc(buffer_size);
+
+  StreamPartitioning<realtype, sunindextype> stream(length, block); 
+  ReducePartitioning<realtype, sunindextype> reduce(h_buffer, d_buffer, length, block);
+  N_VSetPartitioning_Cuda(Y, (void*) &stream, (void*) &reduce);
+
+  /* check to see if a reduction operation still works */
+  N_VConst(ONE, Y);
+  ans = N_VDotProd(Y, Y);
+  sol = ONE*length;
+  if (ans != sol) {
+    printf(">>> FAILED test -- N_VSetPartitioning_Cuda, Proc %d\n", myid);
+    printf("    N_VDotProd returned %.6f but solution is %.6f.\n", ans, sol);
+    return(1);
+  } else if (myid == 0) {
+    printf("PASSED test -- N_VSetPartitioning_Cuda Case 1 \n");
+  }
+  
+  free(h_buffer);
+  cudaFree(d_buffer);
+  
+  /* Case 2: create ReducePartitioning with user-provided internal buffer */
+
+  StreamPartitioning<realtype, sunindextype> stream2(length, block); 
+  ReducePartitioning<realtype, sunindextype> reduce2(length, block, sunalloc, sunfree);
+  N_VSetPartitioning_Cuda(Y, (void*) &stream2, (void*) &reduce2);
+  
+  /* check to see if a reduction operation still works */
+  N_VConst(ONE, Y);
+  ans = N_VDotProd(Y, Y);
+  sol = ONE*length;
+  if (ans != sol) {
+    printf(">>> FAILED test -- N_VSetPartitioning_Cuda, Proc %d\n", myid);
+    printf("    N_VDotProd returned %.6f but solution is %.6f.\n", ans, sol);
+    return(1);
+  } else if (myid == 0) {
+    printf("PASSED test -- N_VSetPartitioning_Cuda Case 2\n");
+  }
+
+  N_VDestroy(Y);
+  return(0);
+}
+
 /* ----------------------------------------------------------------------
  * Implementation specific utility functions for vector tests
  * --------------------------------------------------------------------*/
@@ -409,3 +491,20 @@ void sync_device()
   cudaDeviceSynchronize();
   return;
 }
+
+void* sunalloc(size_t mem_size)
+{
+  void* ptr;
+  cudaError_t err;
+  err = cudaMallocManaged(&ptr, mem_size);
+  if (err != cudaSuccess) {
+    printf("Error in sunalloc\n");
+    ptr = NULL;
+  }
+  return ptr;
+}
+
+void sunfree(void* ptr)
+{
+  cudaFree(ptr);
+}
\ No newline at end of file
diff --git a/include/nvector/cuda/ThreadPartitioning.hpp b/include/nvector/cuda/ThreadPartitioning.hpp
index 10a8c72fd..b5ee9f3a6 100644
--- a/include/nvector/cuda/ThreadPartitioning.hpp
+++ b/include/nvector/cuda/ThreadPartitioning.hpp
@@ -22,6 +22,8 @@
 #include <iostream>
 #include <cuda_runtime.h>
 
+#include <sundials/sundials_types.h>
+
 namespace suncudavec
 {
 
@@ -35,25 +37,35 @@ public:
     shMemSize_(0),
     stream_(0),
     bufferSize_(0),
+    allocfn_(nullptr),
+    freefn_(nullptr),
     d_buffer_(nullptr),
-    h_buffer_(nullptr)
+    h_buffer_(nullptr),
+    ownBuffer_(true)
   {}
 
-  ThreadPartitioning(unsigned block)
+  ThreadPartitioning(unsigned block,
+                     SUNAllocFn allocfn = nullptr,
+                     SUNFreeFn freefn = nullptr)
   : block_(block),
     grid_(1),
     shMemSize_(0),
     stream_(0),
     bufferSize_(0),
+    allocfn_(allocfn),
+    freefn_(freefn),
     d_buffer_(nullptr),
-    h_buffer_(nullptr)
+    h_buffer_(nullptr),
+    ownBuffer_(true)
   {}
-
+  
   explicit ThreadPartitioning(ThreadPartitioning<T, I>& p)
   : block_(p.block_),
     grid_(p.grid_),
     shMemSize_(p.shMemSize_),
-    stream_(p.stream_)
+    stream_(p.stream_),
+    allocfn_(p.allocfn_),
+    freefn_(p.freefn_)
   {}
 
   virtual ~ThreadPartitioning(){}
@@ -78,7 +90,7 @@ public:
     return stream_;
   }
 
-  unsigned int buffSize()
+  unsigned int bufferSize()
   {
     return bufferSize_;
   }
@@ -110,51 +122,14 @@ public:
 
   virtual void copyFromDevBuffer(unsigned int n) const
   {
-    std::cerr << "Trying to copy buffer from base class!\n";
+    std::cerr << "Trying to copy buffer from base class in "
+              << "suncudavec::ThreadPartitioning::copyFromDevBuffer\n";
   }
 
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize,
-                              cudaStream_t& stream)
-  {
-    block = 1;
-    grid  = 1;
-    shMemSize = 0;
-    stream = 0;
-    std::cerr << "Trying to set partitioning from base class!\n";
-
-    return 0;
-  }
-
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize)
-  {
-    block = 1;
-    grid  = 1;
-    shMemSize = 0;
-    std::cerr << "Trying to set partitioning from base class!\n";
-
-    return 0;
-  }
-  
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, cudaStream_t& stream)
-  {
-    block = 1;
-    grid  = 1;
-    stream = 0;
-    std::cerr << "Trying to set partitioning from base class!\n";
-
-    return 0;
-  }
+  /* pure virtual functions to get the relevant partitioning information */
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize, cudaStream_t& stream) = 0;
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize) = 0;
   
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block)
-  {
-    block = 1;
-    grid  = 1;
-    std::cerr << "Trying to set partitioning from base class!\n";
-
-    return 0;
-  }
-
-
 protected:
   unsigned block_;
   unsigned grid_;
@@ -163,6 +138,11 @@ protected:
   cudaStream_t stream_;
   T* d_buffer_;
   T* h_buffer_;
+  bool ownBuffer_;
+
+  /* custom allocators for the internal buffers */
+  SUNAllocFn allocfn_;
+  SUNFreeFn freefn_;
 
 }; // class ThreadPartitioning
 
@@ -194,7 +174,7 @@ public:
   {
   }
 
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize,
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize,
                               cudaStream_t& stream)
   {
     block = block_;
@@ -205,7 +185,7 @@ public:
     return 0;
   }
   
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize)
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize)
   {
     block = block_;
     grid  = (N + block_ - 1) / block_;
@@ -214,23 +194,6 @@ public:
     return 0;
   }
 
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, cudaStream_t& stream)
-  {
-    block = block_;
-    grid  = (N + block_ - 1) / block_;
-    stream = stream_;
-
-    return 0;
-  }
-  
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block)
-  {
-    block = block_;
-    grid  = (N + block_ - 1) / block_;
-
-    return 0;
-  }
-
 }; // class StreamPartitioning
 
 
@@ -244,46 +207,82 @@ class ReducePartitioning : public ThreadPartitioning<T, I>
   using ThreadPartitioning<T, I>::bufferSize_;
   using ThreadPartitioning<T, I>::d_buffer_;
   using ThreadPartitioning<T, I>::h_buffer_;
+  using ThreadPartitioning<T, I>::ownBuffer_;
+  using ThreadPartitioning<T, I>::allocfn_;
+  using ThreadPartitioning<T, I>::freefn_;
 
 public:
-  ReducePartitioning(I N, unsigned block, cudaStream_t stream)
-  : ThreadPartitioning<T, I>(block)
+  ReducePartitioning(I N, unsigned block,
+                     SUNAllocFn allocfn = nullptr, SUNFreeFn freefn = nullptr)
+  : ThreadPartitioning<T, I>(block, allocfn, freefn)
   {
     grid_ = (N + (block_ * 2 - 1)) / (block_ * 2);
     shMemSize_ = block_*sizeof(T);
-    stream_ = stream;
-    allocateBuffer();
+    allocateBuffer(false, allocfn != nullptr);
   }
   
-  ReducePartitioning(I N, unsigned block)
+  ReducePartitioning(I N, unsigned block, cudaStream_t stream,
+                     SUNAllocFn allocfn = nullptr, SUNFreeFn freefn = nullptr)
+  : ThreadPartitioning<T, I>(block, allocfn, freefn)
+  {
+    grid_ = (N + (block_ * 2 - 1)) / (block_ * 2);
+    shMemSize_ = block_*sizeof(T);
+    allocateBuffer(false, allocfn != nullptr);
+  }
+  
+  ReducePartitioning(T *h_buffer, T *d_buffer, I N, unsigned block, cudaStream_t stream = 0)
   : ThreadPartitioning<T, I>(block)
   {
     grid_ = (N + (block_ * 2 - 1)) / (block_ * 2);
     shMemSize_ = block_*sizeof(T);
-    allocateBuffer();
+    stream_ = stream;
+    h_buffer_ = h_buffer;
+    d_buffer_ = d_buffer;
+    ownBuffer_ = false;
   }
-
+  
   explicit ReducePartitioning(ReducePartitioning<T, I>& p)
   : ThreadPartitioning<T, I>(p)
   {
     shMemSize_ = p.shMemSize_;
-    allocateBuffer();
+    /* if device buffer and host buffer are the same, then assume managed memory */
+    allocateBuffer(p.d_buffer_ == p.h_buffer_, p.allocfn_ != nullptr);
   }
 
   ~ReducePartitioning()
   {
     cudaError_t err;
-    if (bufferSize_ > 0)
-      free(h_buffer_);
-    if (bufferSize_ > 0)
-    {
-      err = cudaFree(d_buffer_);
-      if(err != cudaSuccess)
-        std::cerr << "Failed to free device vector (error code " << err << ")!\n";
+
+    if (ownBuffer_ && bufferSize_ > 0) {
+
+      if (d_buffer_ == h_buffer_) {
+        /* managed memory */
+        if (freefn_) {
+          freefn_(d_buffer_);
+        } else {
+          err = cudaFree(d_buffer_);
+          if(err != cudaSuccess)
+            std::cerr << "Failed to free device vector "
+                      << "in suncudavec::ReducePartitioning::~ReducePartitioning "
+                      << "(CUDA error code " << err << ")\n";
+        }
+        d_buffer_ = h_buffer_ = nullptr;
+      } else {
+        /* unmanaged memory */
+        err = cudaFree(d_buffer_);
+        if(err != cudaSuccess)
+          std::cerr << "Failed to free device vector "
+                    << "in suncudavec::ReducePartitioning::~ReducePartitioning "
+                    << "(CUDA error code " << err << ")\n";
+        free(h_buffer_);
+        d_buffer_ = nullptr;
+        h_buffer_ = nullptr;
+      }
+
     }
   }
 
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize,
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize,
                               cudaStream_t& stream)
   {
     block = block_;
@@ -294,7 +293,7 @@ public:
     return 0;
   }
   
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize)
+  virtual int calcPartitioning(I N, unsigned& grid, unsigned& block, unsigned& shMemSize)
   {
     block = block_;
     grid  = (N + (block_ * 2 - 1)) / (block_ * 2);
@@ -303,42 +302,63 @@ public:
     return 0;
   }
 
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block, cudaStream_t& stream)
-  {
-    block = block_;
-    grid  = (N + (block_ * 2 - 1)) / (block_ * 2);
-    stream = stream_;
-
-    return 0;
-  }
-  
-  virtual int setPartitioning(I N, unsigned& grid, unsigned& block)
-  {
-    block = block_;
-    grid  = (N + (block_ * 2 - 1)) / (block_ * 2);
-
-    return 0;
-  }
-
   virtual void copyFromDevBuffer(unsigned int n) const
   {
+    /* If the host and device pointers are the same, then we dont need
+       do any copy (this happens in the managed memory case), but we
+       still need to synchronize the device to adhere to the unified
+       memory access rules. */
+    if (h_buffer_ == d_buffer_) { cudaStreamSynchronize(stream_); return; }
     cudaError_t err = cudaMemcpy(h_buffer_, d_buffer_, n*sizeof(T), cudaMemcpyDeviceToHost);
     if(err != cudaSuccess)
-      std::cerr << "Failed to copy vector from device to host (error code " << err << ")!\n";
+      std::cerr << "Failed to copy vector from device to host in "
+                << "suncudavec::ReducePartitioning::copyFromDevBuffer " 
+                << "(CUDA error code " << err << ")\n";
+  }
+
+  static unsigned calcBufferSize(I N, unsigned block)
+  {
+    return (N + (block * 2 - 1)) / (block * 2) * sizeof(T);
   }
 
 private:
-  int allocateBuffer()
+  int allocateBuffer(bool use_managed_memory = false, bool custom_allocator = false)
   {
+    cudaError_t err;
+
     bufferSize_ = grid_ * sizeof(T);
-    h_buffer_ = static_cast<T*>(malloc(bufferSize_));
-    if(h_buffer_ == NULL)
-      std::cerr << "Failed to allocate host vector!\n";
+    if (bufferSize_ == 0) return 0;
 
-    cudaError_t err;
-    err = cudaMalloc((void**) &d_buffer_, bufferSize_);
-    if(err != cudaSuccess)
-      std::cerr << "Failed to allocate device vector (error code " << err << ")!\n";
+    if (custom_allocator) {
+
+      d_buffer_ = static_cast<T*>(allocfn_(bufferSize_));
+      if(h_buffer_ == NULL)
+        std::cerr << "Failed to allocate managed buffer with custom allocator in "
+                  << "suncudavec::ReducePartitioning::allocateBuffer\n";
+      h_buffer_ = d_buffer_;
+
+    } else if (use_managed_memory) {
+
+      err = cudaMallocManaged((void**) &d_buffer_, bufferSize_);
+      if(err != cudaSuccess)
+        std::cerr << "Failed to allocate internal managed buffer in "
+                  << "suncudavec::ReducePartitioning::allocateBuffer "
+                  << "(CUDA error code " << err << ")\n";
+      h_buffer_ = d_buffer_;
+
+    } else {
+
+      h_buffer_ = static_cast<T*>(malloc(bufferSize_));
+      if(h_buffer_ == NULL)
+        std::cerr << "Failed to allocate internal host buffer in "
+                  << "suncudavec::ReducePartitioning::allocateBuffer\n";
+      err = cudaMalloc((void**) &d_buffer_, bufferSize_);
+      if(err != cudaSuccess)
+        std::cerr << "Failed to allocate internal device buffer "
+                  << "in suncudavec::ReducePartitioning::allocateBuffer "
+                  << "(CUDA error code " << err << ")\n";
+
+    }
 
     return 0;
   }
diff --git a/include/nvector/cuda/Vector.hpp b/include/nvector/cuda/Vector.hpp
index 6a0e3adf9..0b69b200c 100644
--- a/include/nvector/cuda/Vector.hpp
+++ b/include/nvector/cuda/Vector.hpp
@@ -49,13 +49,15 @@ public:
     ownPartitioning_(true),
     ownData_(allocate_data),
     managed_mem_(use_managed_memory),
+    allocfn_(nullptr),
+    freefn_(nullptr),
     h_vec_(h_vec),
     d_vec_(d_vec)
   {
     // Set partitioning
     partStream_ = new StreamPartitioning<T, I>(N, 256);
     partReduce_ = new ReducePartitioning<T, I>(N, 256);
-
+    
     // Allocate data arrays
     if (allocate_data)
       allocate();
@@ -69,6 +71,8 @@ public:
     ownPartitioning_(true),
     ownData_(allocate_data),
     managed_mem_(use_managed_memory),
+    allocfn_(nullptr),
+    freefn_(nullptr),
     h_vec_(h_vec),
     d_vec_(d_vec)
   {
@@ -81,6 +85,50 @@ public:
       allocate();
   }
   
+  Vector(I N,
+         SUNAllocFn allocfn, SUNFreeFn freefn,
+         bool allocate_data = true)
+  : size_(N),
+    mem_size_(N*sizeof(T)),
+    ownPartitioning_(true),
+    ownData_(allocate_data),
+    managed_mem_(false),
+    allocfn_(allocfn),
+    freefn_(freefn),
+    h_vec_(nullptr),
+    d_vec_(nullptr)
+  {
+    // Set partitioning
+    partStream_ = new StreamPartitioning<T, I>(N, 256);
+    partReduce_ = new ReducePartitioning<T, I>(N, 256, allocfn, freefn);
+
+    // Allocate data arrays
+    if (allocate_data)
+      allocate();
+  }
+  
+  Vector(I N, cudaStream_t stream,
+         SUNAllocFn allocfn, SUNFreeFn freefn,
+         bool allocate_data = true)
+  : size_(N),
+    mem_size_(N*sizeof(T)),
+    ownPartitioning_(true),
+    ownData_(allocate_data),
+    managed_mem_(false),
+    allocfn_(allocfn),
+    freefn_(freefn),
+    h_vec_(nullptr),
+    d_vec_(nullptr)
+  {
+    // Set partitioning
+    partStream_ = new StreamPartitioning<T, I>(N, 256, stream);
+    partReduce_ = new ReducePartitioning<T, I>(N, 256, stream, allocfn, freefn);
+
+    // Allocate data arrays
+    if (allocate_data)
+      allocate();
+  }
+  
   // Copy constructor does not copy data array values
   explicit Vector(const Vector& v)
   : size_(v.size()),
@@ -90,6 +138,8 @@ public:
     ownPartitioning_(false),
     ownData_(true),
     managed_mem_(v.managed_mem_),
+    allocfn_(v.allocfn_),
+    freefn_(v.freefn_),
     h_vec_(nullptr),
     d_vec_(nullptr)
   {
@@ -106,21 +156,29 @@ public:
     }
     
     if (ownData_) {
-      if (!managed_mem_)
-        free(h_vec_);
-      
-      err = cudaFree(d_vec_);
-      if(err != cudaSuccess)
-        std::cerr << "Failed to free device vector (error code " << err << ")!\n";
-    
-      d_vec_ = nullptr;
-      h_vec_ = nullptr;
+      if (freefn_) {
+        freefn_(d_vec_);
+        d_vec_ = nullptr;
+        h_vec_ = nullptr;
+      } else {
+        if (!managed_mem_)
+          free(h_vec_);
+        err = cudaFree(d_vec_);
+        if(err != cudaSuccess)
+          std::cerr << "Failed to free device vector "
+                    << "in suncudavec::Vector::~Vector "
+                    << "(error code " << err << ")\n";
+        d_vec_ = nullptr;
+        h_vec_ = nullptr;
+      }
     }
   }
 
   void allocate()
   {
-    if (managed_mem_) {
+    if (allocfn_) {
+      allocateCustom();
+    } else if (managed_mem_) {
       allocateManaged();
     } else {
       allocateUnmanaged();
@@ -132,7 +190,9 @@ public:
     cudaError_t err;
     err = cudaMallocManaged((void**) &d_vec_, mem_size_);
     if (err != cudaSuccess)
-      std::cerr << "Failed to allocate managed vector (error code " << err << ")!\n";
+      std::cerr << "Failed to allocate managed vector "
+                << "in suncudavec::Vector::allocateManaged "
+                << "(error code " << err << ")\n";
     h_vec_ = d_vec_;
   }
 
@@ -142,11 +202,24 @@ public:
     
     h_vec_ = static_cast<T*>(malloc(mem_size_));
     if(h_vec_ == nullptr)
-      std::cerr << "Failed to allocate host vector!\n";
+      std::cerr << "Failed to allocate host vector "
+                << "in suncudavec::Vector::allocateUnmanaged\n";
     
     err = cudaMalloc((void**) &d_vec_, mem_size_);
     if(err != cudaSuccess)
-      std::cerr << "Failed to allocate device vector (error code " << err << ")!\n";
+      std::cerr << "Failed to allocate device vector "
+                << "in suncudavec::Vector::allocateUnmanaged "
+                << "(error code " << err << ")\n";
+  }
+
+  void allocateCustom()
+  {
+    /* custom allocator has to be for managed memory */
+    d_vec_ = (realtype *) allocfn_(mem_size_);
+    if (d_vec_ == nullptr)
+      std::cerr << "Failed to allocate vector with user-provied allocator "
+                << "in suncudavec::Vector::allocateCustom()\n"; 
+    h_vec_ = d_vec_;
   }
   
   int size() const
@@ -181,16 +254,41 @@ public:
 
   void copyToDev()
   {
+    /* If the host and device pointers are the same, then we dont need
+       do any copy (this happens in the managed memory case), but we
+       still need to synchronize the device to adhere to the unified
+       memory access rules. */
+    if (h_vec_ == d_vec_) { cudaStreamSynchronize(partReduce_->stream()); return; }
     cudaError_t err = cudaMemcpy(d_vec_, h_vec_, mem_size_, cudaMemcpyHostToDevice);
     if(err != cudaSuccess)
-      std::cerr << "Failed to copy vector from host to device (error code " << err << ")!\n";
+      std::cerr << "Failed to copy vector from host to device in "
+                << "suncudavec::Vector::copyToDev "
+                << "(error code " << err << ")\n";
   }
 
   void copyFromDev()
   {
+    /* If the host and device pointers are the same, then we dont need
+       do any copy (this happens in the managed memory case), but we
+       still need to synchronize the device to adhere to the unified
+       memory access rules. */
+    if (h_vec_ == d_vec_) { cudaStreamSynchronize(partReduce_->stream()); return; }
     cudaError_t err = cudaMemcpy(h_vec_, d_vec_, mem_size_, cudaMemcpyDeviceToHost);
     if(err != cudaSuccess)
-      std::cerr << "Failed to copy vector from device to host (error code " << err << ")!\n";
+      std::cerr << "Failed to copy vector from device to host in "
+                << "suncudavec::Vector::copyFromDev "
+                << "(error code " << err << ")\n";
+  }
+
+  void setPartitioning(ThreadPartitioning<T, I>* stream, ThreadPartitioning<T, I>* reduce)
+  {
+     if (ownPartitioning_) {
+       delete partStream_;
+       delete partReduce_;
+     }
+    partStream_ = stream;
+    partReduce_ = reduce;
+    ownPartitioning_ = false;
   }
 
   ThreadPartitioning<T, I>& partStream() const
@@ -214,6 +312,8 @@ private:
   bool ownPartitioning_;
   bool ownData_;
   bool managed_mem_;
+  SUNAllocFn allocfn_;
+  SUNFreeFn freefn_;
   
 };
 
diff --git a/include/nvector/cuda/VectorKernels.cuh b/include/nvector/cuda/VectorKernels.cuh
index 8b304b75d..07c02cbc1 100644
--- a/include/nvector/cuda/VectorKernels.cuh
+++ b/include/nvector/cuda/VectorKernels.cuh
@@ -753,7 +753,7 @@ inline T dotProd(const Vector<T,I>& x, const Vector<T,I>& y)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -788,7 +788,7 @@ inline T maxNorm(const Vector<T,I>& x)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // (Re)run reduction kernel
     math_kernels::maxNormKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -824,7 +824,7 @@ inline T wL2NormSquareMask(const Vector<T,I>& x, const Vector<T,I>& w, const Vec
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // (Re)run reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -861,7 +861,7 @@ inline T findMin(const Vector<T,I>& x)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::findMinKernel<T,I><<<grid, block, shMemSize, stream>>>(maxVal, p.devBuffer(), p.devBuffer(), n);
@@ -898,7 +898,7 @@ inline T wL2NormSquare(const Vector<T,I>& x, const Vector<T,I>& y)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -934,7 +934,7 @@ inline T L1Norm(const Vector<T,I>& x)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -970,7 +970,7 @@ inline T invTest(const Vector<T,I>& x, Vector<T,I>& z)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -1006,7 +1006,7 @@ inline T constrMask(const Vector<T,I>& c, const Vector<T,I>& x, Vector<T,I>& m)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::sumReduceKernel<T,I><<<grid, block, shMemSize, stream>>>(p.devBuffer(), p.devBuffer(), n);
@@ -1046,7 +1046,7 @@ inline T minQuotient(const Vector<T,I>& num, const Vector<T,I>& den)
   while (n > nmax)
   {
     // Recompute partitioning
-    p.setPartitioning(n, grid, block, shMemSize);
+    p.calcPartitioning(n, grid, block, shMemSize);
 
     // Rerun reduction kernel
     math_kernels::findMinKernel<T,I><<<grid, block, shMemSize, stream>>>(maxVal, p.devBuffer(), p.devBuffer(), n);
diff --git a/include/nvector/nvector_cuda.h b/include/nvector/nvector_cuda.h
index a0234287f..ed2b13aff 100644
--- a/include/nvector/nvector_cuda.h
+++ b/include/nvector/nvector_cuda.h
@@ -80,6 +80,10 @@ SUNDIALS_EXPORT N_Vector N_VMake_Cuda(sunindextype length,
 SUNDIALS_EXPORT N_Vector N_VMakeManaged_Cuda(sunindextype length,
                                              realtype *vdata);
 
+SUNDIALS_EXPORT N_Vector N_VMakeWithAllocator_Cuda(sunindextype length,
+                                                   SUNAllocFn allocfn,
+                                                   SUNFreeFn freefn);
+
 SUNDIALS_EXPORT sunindextype N_VGetLength_Cuda(N_Vector v);
 
 SUNDIALS_EXPORT realtype *N_VGetHostArrayPointer_Cuda(N_Vector v);
@@ -90,6 +94,8 @@ SUNDIALS_EXPORT booleantype N_VIsManagedMemory_Cuda(N_Vector x);
 
 SUNDIALS_EXPORT void N_VSetCudaStream_Cuda(N_Vector x, cudaStream_t *stream);
 
+SUNDIALS_EXPORT void N_VSetPartitioning_Cuda(N_Vector x, void *stream, void *reduce);
+
 SUNDIALS_EXPORT void N_VCopyToDevice_Cuda(N_Vector v);
 
 SUNDIALS_EXPORT void N_VCopyFromDevice_Cuda(N_Vector v);
diff --git a/include/sundials/sundials_types.h b/include/sundials/sundials_types.h
index 958ee12f6..54e23f66a 100644
--- a/include/sundials/sundials_types.h
+++ b/include/sundials/sundials_types.h
@@ -54,6 +54,7 @@
 #endif
 
 #include <float.h>
+#include <stddef.h>
 #include <stdint.h>
 
 #ifdef __cplusplus  /* wrapper to enable C++ usage */
@@ -152,6 +153,26 @@ typedef SUNDIALS_INDEX_TYPE sunindextype;
 #define SUNTRUE 1
 #endif
 
+/*
+ *------------------------------------------------------------------
+ * Type : SUNAllocFn
+ *------------------------------------------------------------------
+ * A generic function provided by a user that allocates memory. 
+ *------------------------------------------------------------------
+ */
+
+typedef void* (*SUNAllocFn)(size_t size);
+
+/*
+ *------------------------------------------------------------------
+ * Type : SUNFreeFn
+ *------------------------------------------------------------------
+ * A generic function provided by a user that frees memory.
+ *------------------------------------------------------------------
+ */
+
+typedef void (*SUNFreeFn)(void* ptr);
+
 
 #ifdef __cplusplus
 }
diff --git a/src/nvector/cuda/nvector_cuda.cu b/src/nvector/cuda/nvector_cuda.cu
index b67e14919..b109c48d0 100644
--- a/src/nvector/cuda/nvector_cuda.cu
+++ b/src/nvector/cuda/nvector_cuda.cu
@@ -37,6 +37,7 @@ using namespace suncudavec;
  */
 
 typedef suncudavec::Vector<realtype, sunindextype> vector_type;
+typedef suncudavec::ThreadPartitioning<realtype, sunindextype> part_type;
 
 /* ----------------------------------------------------------------
  * Returns vector type ID. Used to identify vector implementation
@@ -156,13 +157,26 @@ N_Vector N_VMakeManaged_Cuda(sunindextype length, realtype *vdata)
   v = N_VNewEmpty_Cuda();
   if (v == NULL) return(NULL);
 
-  /* create suncudavec::Vector with managed memory using the user-provided data
-     arrays */
+  /* create suncudavec::Vector with managed memory using the user-provided data arrays */
   v->content = new vector_type(length, true, false, vdata, vdata);
 
   return(v);
 }
 
+N_Vector N_VMakeWithAllocator_Cuda(sunindextype length, SUNAllocFn allocfn, SUNFreeFn freefn)
+{
+  N_Vector v;
+
+  v = NULL;
+  v = N_VNewEmpty_Cuda();
+  if (v == NULL) return(NULL);
+
+  /* create suncudavec::Vector with a custom allocator/deallocator */
+  v->content = new vector_type(length, allocfn, freefn, true);
+
+  return(v);
+}
+
 /* -----------------------------------------------------------------
  * Function to return the global length of the vector.
  */
@@ -212,6 +226,18 @@ void N_VSetCudaStream_Cuda(N_Vector x, cudaStream_t *stream)
   xv->partReduce().setStream(*stream);
 }
 
+/*
+ * ----------------------------------------------------------------------------
+ * Sets the partitioning to use for the execution of streaming and reduction
+ * CUDA kernels.
+ */
+void N_VSetPartitioning_Cuda(N_Vector x, void *stream, void *reduce)
+{
+  vector_type* xv = static_cast<vector_type*>(x->content);
+  xv->setPartitioning(static_cast<part_type*>(stream),
+                      static_cast<part_type*>(reduce));
+}
+
 /* ----------------------------------------------------------------------------
  * Copy vector data to the device
  */
